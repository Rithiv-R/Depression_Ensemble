{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n62B0foCCYFF"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "dataframe1 = pd.read_csv(\"mainnn.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "inWb_Sy9Fs2Q",
        "outputId": "4eb00daf-9891-497e-9e42-a6e2a585d4cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               statement  depression_level\n",
              "0                                i didnt feel humiliated                 2\n",
              "1      i can go from feeling so hopeless to so damned...                 2\n",
              "2       im grabbing a minute to post i feel greedy wrong                 4\n",
              "3      i am ever feeling nostalgic about the fireplac...                 0\n",
              "4                                   i am feeling grouchy                 4\n",
              "...                                                  ...               ...\n",
              "19995  im having ssa examination tomorrow in the morn...                 2\n",
              "19996  i constantly worry about their fight against n...                 0\n",
              "19997  i feel its important to share this info for th...                 0\n",
              "19998  i truly feel that if you are passionate enough...                 0\n",
              "19999  i feel like i just wanna buy any cute make up ...                 0\n",
              "\n",
              "[20000 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4c0cabaa-cd84-4952-b41f-c3a06219908b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>statement</th>\n",
              "      <th>depression_level</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>i didnt feel humiliated</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>i can go from feeling so hopeless to so damned...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>i am feeling grouchy</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19995</th>\n",
              "      <td>im having ssa examination tomorrow in the morn...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19996</th>\n",
              "      <td>i constantly worry about their fight against n...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19997</th>\n",
              "      <td>i feel its important to share this info for th...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19998</th>\n",
              "      <td>i truly feel that if you are passionate enough...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19999</th>\n",
              "      <td>i feel like i just wanna buy any cute make up ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20000 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4c0cabaa-cd84-4952-b41f-c3a06219908b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4c0cabaa-cd84-4952-b41f-c3a06219908b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4c0cabaa-cd84-4952-b41f-c3a06219908b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tolower(string):\n",
        "  string = string.lower() \n",
        "  return string\n",
        "dataframe1['statement']=dataframe1['statement'].apply(lambda sent : tolower(sent))"
      ],
      "metadata": {
        "id": "txGnXPa4G4hC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "stopper = set(stopwords.words(\"english\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0bls24mLG62w",
        "outputId": "80da438e-8063-478a-99d9-33666b84cc72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stopper"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ifsUE2Q8G9CO",
        "outputId": "05fd7588-f696-4d00-da7b-3f7eec070ffe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'a',\n",
              " 'about',\n",
              " 'above',\n",
              " 'after',\n",
              " 'again',\n",
              " 'against',\n",
              " 'ain',\n",
              " 'all',\n",
              " 'am',\n",
              " 'an',\n",
              " 'and',\n",
              " 'any',\n",
              " 'are',\n",
              " 'aren',\n",
              " \"aren't\",\n",
              " 'as',\n",
              " 'at',\n",
              " 'be',\n",
              " 'because',\n",
              " 'been',\n",
              " 'before',\n",
              " 'being',\n",
              " 'below',\n",
              " 'between',\n",
              " 'both',\n",
              " 'but',\n",
              " 'by',\n",
              " 'can',\n",
              " 'couldn',\n",
              " \"couldn't\",\n",
              " 'd',\n",
              " 'did',\n",
              " 'didn',\n",
              " \"didn't\",\n",
              " 'do',\n",
              " 'does',\n",
              " 'doesn',\n",
              " \"doesn't\",\n",
              " 'doing',\n",
              " 'don',\n",
              " \"don't\",\n",
              " 'down',\n",
              " 'during',\n",
              " 'each',\n",
              " 'few',\n",
              " 'for',\n",
              " 'from',\n",
              " 'further',\n",
              " 'had',\n",
              " 'hadn',\n",
              " \"hadn't\",\n",
              " 'has',\n",
              " 'hasn',\n",
              " \"hasn't\",\n",
              " 'have',\n",
              " 'haven',\n",
              " \"haven't\",\n",
              " 'having',\n",
              " 'he',\n",
              " 'her',\n",
              " 'here',\n",
              " 'hers',\n",
              " 'herself',\n",
              " 'him',\n",
              " 'himself',\n",
              " 'his',\n",
              " 'how',\n",
              " 'i',\n",
              " 'if',\n",
              " 'in',\n",
              " 'into',\n",
              " 'is',\n",
              " 'isn',\n",
              " \"isn't\",\n",
              " 'it',\n",
              " \"it's\",\n",
              " 'its',\n",
              " 'itself',\n",
              " 'just',\n",
              " 'll',\n",
              " 'm',\n",
              " 'ma',\n",
              " 'me',\n",
              " 'mightn',\n",
              " \"mightn't\",\n",
              " 'more',\n",
              " 'most',\n",
              " 'mustn',\n",
              " \"mustn't\",\n",
              " 'my',\n",
              " 'myself',\n",
              " 'needn',\n",
              " \"needn't\",\n",
              " 'no',\n",
              " 'nor',\n",
              " 'not',\n",
              " 'now',\n",
              " 'o',\n",
              " 'of',\n",
              " 'off',\n",
              " 'on',\n",
              " 'once',\n",
              " 'only',\n",
              " 'or',\n",
              " 'other',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'out',\n",
              " 'over',\n",
              " 'own',\n",
              " 're',\n",
              " 's',\n",
              " 'same',\n",
              " 'shan',\n",
              " \"shan't\",\n",
              " 'she',\n",
              " \"she's\",\n",
              " 'should',\n",
              " \"should've\",\n",
              " 'shouldn',\n",
              " \"shouldn't\",\n",
              " 'so',\n",
              " 'some',\n",
              " 'such',\n",
              " 't',\n",
              " 'than',\n",
              " 'that',\n",
              " \"that'll\",\n",
              " 'the',\n",
              " 'their',\n",
              " 'theirs',\n",
              " 'them',\n",
              " 'themselves',\n",
              " 'then',\n",
              " 'there',\n",
              " 'these',\n",
              " 'they',\n",
              " 'this',\n",
              " 'those',\n",
              " 'through',\n",
              " 'to',\n",
              " 'too',\n",
              " 'under',\n",
              " 'until',\n",
              " 'up',\n",
              " 've',\n",
              " 'very',\n",
              " 'was',\n",
              " 'wasn',\n",
              " \"wasn't\",\n",
              " 'we',\n",
              " 'were',\n",
              " 'weren',\n",
              " \"weren't\",\n",
              " 'what',\n",
              " 'when',\n",
              " 'where',\n",
              " 'which',\n",
              " 'while',\n",
              " 'who',\n",
              " 'whom',\n",
              " 'why',\n",
              " 'will',\n",
              " 'with',\n",
              " 'won',\n",
              " \"won't\",\n",
              " 'wouldn',\n",
              " \"wouldn't\",\n",
              " 'y',\n",
              " 'you',\n",
              " \"you'd\",\n",
              " \"you'll\",\n",
              " \"you're\",\n",
              " \"you've\",\n",
              " 'your',\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves'}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def removestop(sent):\n",
        "  result = \" \"\n",
        "  for i in sent.split():\n",
        "    if i not in stopper:\n",
        "      result=result+i+\" \"\n",
        "  return result.strip()\n",
        "\n",
        "dataframe1['statement'] = dataframe1['statement'].apply(lambda sent:removestop(sent))"
      ],
      "metadata": {
        "id": "H1_Iac5pG_lJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "wszKcP_2HBQt",
        "outputId": "dc2e740f-422b-488e-fa74-48ad35a55f42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               statement  depression_level\n",
              "0                                  didnt feel humiliated                 2\n",
              "1      go feeling hopeless damned hopeful around some...                 2\n",
              "2              im grabbing minute post feel greedy wrong                 4\n",
              "3      ever feeling nostalgic fireplace know still pr...                 0\n",
              "4                                        feeling grouchy                 4\n",
              "...                                                  ...               ...\n",
              "19995  im ssa examination tomorrow morning im quite w...                 2\n",
              "19996  constantly worry fight nature push limits inne...                 0\n",
              "19997         feel important share info experience thing                 0\n",
              "19998  truly feel passionate enough something stay tr...                 0\n",
              "19999  feel like wanna buy cute make see online even one                 0\n",
              "\n",
              "[20000 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a2e8e8ac-26a4-4d64-a263-33876a2fc01a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>statement</th>\n",
              "      <th>depression_level</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>didnt feel humiliated</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>go feeling hopeless damned hopeful around some...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>im grabbing minute post feel greedy wrong</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ever feeling nostalgic fireplace know still pr...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>feeling grouchy</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19995</th>\n",
              "      <td>im ssa examination tomorrow morning im quite w...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19996</th>\n",
              "      <td>constantly worry fight nature push limits inne...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19997</th>\n",
              "      <td>feel important share info experience thing</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19998</th>\n",
              "      <td>truly feel passionate enough something stay tr...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19999</th>\n",
              "      <td>feel like wanna buy cute make see online even one</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20000 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a2e8e8ac-26a4-4d64-a263-33876a2fc01a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a2e8e8ac-26a4-4d64-a263-33876a2fc01a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a2e8e8ac-26a4-4d64-a263-33876a2fc01a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('all')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LrmvGqJdHDlK",
        "outputId": "da79330e-31ab-4322-93f9-480a9a72a5c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading collection 'all'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package abc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/abc.zip.\n",
            "[nltk_data]    | Downloading package alpino to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/alpino.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping\n",
            "[nltk_data]    |       taggers/averaged_perceptron_tagger_ru.zip.\n",
            "[nltk_data]    | Downloading package basque_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/basque_grammars.zip.\n",
            "[nltk_data]    | Downloading package bcp47 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package biocreative_ppi to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/biocreative_ppi.zip.\n",
            "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/bllip_wsj_no_aux.zip.\n",
            "[nltk_data]    | Downloading package book_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/book_grammars.zip.\n",
            "[nltk_data]    | Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown.zip.\n",
            "[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown_tei.zip.\n",
            "[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_cat.zip.\n",
            "[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_esp.zip.\n",
            "[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/chat80.zip.\n",
            "[nltk_data]    | Downloading package city_database to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/city_database.zip.\n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package comparative_sentences to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/comparative_sentences.zip.\n",
            "[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2002.zip.\n",
            "[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/crubadan.zip.\n",
            "[nltk_data]    | Downloading package dependency_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dependency_treebank.zip.\n",
            "[nltk_data]    | Downloading package dolch to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dolch.zip.\n",
            "[nltk_data]    | Downloading package europarl_raw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/europarl_raw.zip.\n",
            "[nltk_data]    | Downloading package extended_omw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package floresta to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/floresta.zip.\n",
            "[nltk_data]    | Downloading package framenet_v15 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v15.zip.\n",
            "[nltk_data]    | Downloading package framenet_v17 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v17.zip.\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package ieer to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ieer.zip.\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package indian to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/indian.zip.\n",
            "[nltk_data]    | Downloading package jeita to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/kimmo.zip.\n",
            "[nltk_data]    | Downloading package knbc to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package large_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/large_grammars.zip.\n",
            "[nltk_data]    | Downloading package lin_thesaurus to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/lin_thesaurus.zip.\n",
            "[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mac_morpho.zip.\n",
            "[nltk_data]    | Downloading package machado to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
            "[nltk_data]    | Downloading package moses_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/moses_sample.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mte_teip5.zip.\n",
            "[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/mwa_ppdb.zip.\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nonbreaking_prefixes.zip.\n",
            "[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nps_chat.zip.\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package opinion_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/opinion_lexicon.zip.\n",
            "[nltk_data]    | Downloading package panlex_swadesh to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/paradigms.zip.\n",
            "[nltk_data]    | Downloading package pe08 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pe08.zip.\n",
            "[nltk_data]    | Downloading package perluniprops to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/perluniprops.zip.\n",
            "[nltk_data]    | Downloading package pil to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pil.zip.\n",
            "[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pl196x.zip.\n",
            "[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/porter_test.zip.\n",
            "[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ppattach.zip.\n",
            "[nltk_data]    | Downloading package problem_reports to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/problem_reports.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_1 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_1.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_2 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_2.zip.\n",
            "[nltk_data]    | Downloading package propbank to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pros_cons.zip.\n",
            "[nltk_data]    | Downloading package ptb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ptb.zip.\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data]    | Downloading package qc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/qc.zip.\n",
            "[nltk_data]    | Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/rslp.zip.\n",
            "[nltk_data]    | Downloading package rte to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/rte.zip.\n",
            "[nltk_data]    | Downloading package sample_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/sample_grammars.zip.\n",
            "[nltk_data]    | Downloading package semcor to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package senseval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/senseval.zip.\n",
            "[nltk_data]    | Downloading package sentence_polarity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentence_polarity.zip.\n",
            "[nltk_data]    | Downloading package sentiwordnet to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentiwordnet.zip.\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
            "[nltk_data]    | Downloading package sinica_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sinica_treebank.zip.\n",
            "[nltk_data]    | Downloading package smultron to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/smultron.zip.\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package spanish_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/spanish_grammars.zip.\n",
            "[nltk_data]    | Downloading package state_union to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/state_union.zip.\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Package stopwords is already up-to-date!\n",
            "[nltk_data]    | Downloading package subjectivity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/subjectivity.zip.\n",
            "[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/swadesh.zip.\n",
            "[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/switchboard.zip.\n",
            "[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping help/tagsets.zip.\n",
            "[nltk_data]    | Downloading package timit to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/timit.zip.\n",
            "[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/toolbox.zip.\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data]    | Downloading package udhr to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr.zip.\n",
            "[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr2.zip.\n",
            "[nltk_data]    | Downloading package unicode_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/unicode_samples.zip.\n",
            "[nltk_data]    | Downloading package universal_tagset to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/universal_tagset.zip.\n",
            "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package vader_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet.zip.\n",
            "[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet3.zip.\n",
            "[nltk_data]    | Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/webtext.zip.\n",
            "[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/wmt15_eval.zip.\n",
            "[nltk_data]    | Downloading package word2vec_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/word2vec_sample.zip.\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet2021 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet2022 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet2022.zip.\n",
            "[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ycoe.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection all\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
        "def lemmatize1(sent):\n",
        "  new_sent = \"\"\n",
        "  for i in sent.split(\" \"):\n",
        "    new_sent = new_sent+lemmatizer.lemmatize(i)+\" \"\n",
        "  return new_sent\n",
        "dataframe1['statement'] = dataframe1['statement'].apply(lambda sent:lemmatize1(sent))"
      ],
      "metadata": {
        "id": "cb6by3VUHG1P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "Lq4lo4jnHahm",
        "outputId": "12d078d1-5b41-4a08-afc1-4e0e1ca30d08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               statement  depression_level\n",
              "0                                 didnt feel humiliated                  2\n",
              "1      go feeling hopeless damned hopeful around some...                 2\n",
              "2             im grabbing minute post feel greedy wrong                  4\n",
              "3      ever feeling nostalgic fireplace know still pr...                 0\n",
              "4                                       feeling grouchy                  4\n",
              "...                                                  ...               ...\n",
              "19995  im ssa examination tomorrow morning im quite w...                 2\n",
              "19996  constantly worry fight nature push limit inner...                 0\n",
              "19997        feel important share info experience thing                  0\n",
              "19998  truly feel passionate enough something stay tr...                 0\n",
              "19999  feel like wanna buy cute make see online even ...                 0\n",
              "\n",
              "[20000 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c6867bdf-e6eb-43c5-84d9-ee0281a513c2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>statement</th>\n",
              "      <th>depression_level</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>didnt feel humiliated</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>go feeling hopeless damned hopeful around some...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>im grabbing minute post feel greedy wrong</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ever feeling nostalgic fireplace know still pr...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>feeling grouchy</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19995</th>\n",
              "      <td>im ssa examination tomorrow morning im quite w...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19996</th>\n",
              "      <td>constantly worry fight nature push limit inner...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19997</th>\n",
              "      <td>feel important share info experience thing</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19998</th>\n",
              "      <td>truly feel passionate enough something stay tr...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19999</th>\n",
              "      <td>feel like wanna buy cute make see online even ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20000 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c6867bdf-e6eb-43c5-84d9-ee0281a513c2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c6867bdf-e6eb-43c5-84d9-ee0281a513c2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c6867bdf-e6eb-43c5-84d9-ee0281a513c2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import np_utils\n",
        "encoded_labels = np_utils.to_categorical(dataframe1['depression_level'])\n",
        "encoded_labels.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XHEY_2hTHb_l",
        "outputId": "3cd141b5-f68c-4ff1-958a-462d44e73b42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20000, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_x, test_x, train_y, test_y = train_test_split(dataframe1['statement'],encoded_labels, test_size=0.4)"
      ],
      "metadata": {
        "id": "X9MTvMW0H2WD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import one_hot"
      ],
      "metadata": {
        "id": "OwErsgNhIANR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_x_rep = [one_hot(w,5000) for w in train_x] #5000- vocabulary size\n",
        "test_x_rep = [one_hot(w,5000) for w in test_x]"
      ],
      "metadata": {
        "id": "S5YiPd4iIDDB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oerySRheIFVY",
        "outputId": "545868ca-9bf8-4f66-9cc4-4231934fa769"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., 1., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "Q_JDe2xvIILW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent_length = 40\n",
        "embedded_train_x = pad_sequences(train_x_rep,padding='pre',maxlen=sent_length)\n",
        "embedded_test_x = pad_sequences(test_x_rep,padding='pre',maxlen=sent_length)"
      ],
      "metadata": {
        "id": "OtQSv2nJIKT1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedded_test_x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XVeRCt1NIMwF",
        "outputId": "2bf15aff-a80a-40e5-daee-70a6f8014f4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   0,    0,    0, ..., 4142,  439, 1833],\n",
              "       [   0,    0,    0, ..., 4171, 4130, 2332],\n",
              "       [   0,    0,    0, ...,  700, 4171,  957],\n",
              "       ...,\n",
              "       [   0,    0,    0, ..., 3482,  228, 3362],\n",
              "       [   0,    0,    0, ..., 4834, 4525, 2333],\n",
              "       [   0,    0,    0, ..., 2693, 4869,  822]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM,Dense,Bidirectional\n",
        "from tensorflow.keras.layers import Dropout,Flatten"
      ],
      "metadata": {
        "id": "Yo6_yqtvIP0E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embed_vect = 40\n",
        "model = Sequential()\n",
        "model.add(Embedding(5000,embed_vect,input_length=40))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Bidirectional(LSTM(150)))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(5,activation='sigmoid'))\n",
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics='accuracy')\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7wWsMXGRIR2w",
        "outputId": "b292514d-e3c0-4264-af60-145c551866e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 40, 40)            200000    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 40, 40)            0         \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 300)              229200    \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 300)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 5)                 1505      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 430,705\n",
            "Trainable params: 430,705\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedded_test_x.shape, test_y.shape, embedded_train_x.shape, train_y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PtdZZJnrITux",
        "outputId": "7b121841-46df-43f8-b323-d8ae74c1f25e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((8000, 40), (8000, 5), (12000, 40), (12000, 5))"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(embedded_train_x,train_y,epochs=10,batch_size=128,validation_data=(embedded_test_x,test_y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FuI3_x_ZIWqG",
        "outputId": "25278810-ca2c-4b67-9f7f-e4135845f353"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "94/94 [==============================] - 45s 428ms/step - loss: 1.3791 - accuracy: 0.4226 - val_loss: 1.3310 - val_accuracy: 0.4181\n",
            "Epoch 2/10\n",
            "94/94 [==============================] - 37s 389ms/step - loss: 1.0944 - accuracy: 0.5711 - val_loss: 0.8686 - val_accuracy: 0.6874\n",
            "Epoch 3/10\n",
            "94/94 [==============================] - 36s 387ms/step - loss: 0.6523 - accuracy: 0.7612 - val_loss: 0.6847 - val_accuracy: 0.7594\n",
            "Epoch 4/10\n",
            "94/94 [==============================] - 40s 424ms/step - loss: 0.4823 - accuracy: 0.8298 - val_loss: 0.5898 - val_accuracy: 0.7941\n",
            "Epoch 5/10\n",
            "94/94 [==============================] - 40s 422ms/step - loss: 0.3506 - accuracy: 0.8827 - val_loss: 0.5114 - val_accuracy: 0.8314\n",
            "Epoch 6/10\n",
            "94/94 [==============================] - 40s 424ms/step - loss: 0.2524 - accuracy: 0.9178 - val_loss: 0.4557 - val_accuracy: 0.8508\n",
            "Epoch 7/10\n",
            "94/94 [==============================] - 40s 423ms/step - loss: 0.1983 - accuracy: 0.9348 - val_loss: 0.4493 - val_accuracy: 0.8515\n",
            "Epoch 8/10\n",
            "94/94 [==============================] - 40s 426ms/step - loss: 0.1659 - accuracy: 0.9443 - val_loss: 0.4619 - val_accuracy: 0.8493\n",
            "Epoch 9/10\n",
            "94/94 [==============================] - 39s 419ms/step - loss: 0.1412 - accuracy: 0.9538 - val_loss: 0.5080 - val_accuracy: 0.8530\n",
            "Epoch 10/10\n",
            "94/94 [==============================] - 40s 423ms/step - loss: 0.1317 - accuracy: 0.9554 - val_loss: 0.4655 - val_accuracy: 0.8566\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f00fdc41d60>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"model.h5\")"
      ],
      "metadata": {
        "id": "38mi8WsKIdOz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(embedded_test_x)\n",
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UHGZ23S3KBmm",
        "outputId": "abbd53ef-1666-4046-93f9-64332ec57ece"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "250/250 [==============================] - 19s 77ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.12542339, 0.5886645 , 0.31128687, 0.908932  , 0.8769034 ],\n",
              "       [0.03453974, 0.00184798, 0.9975694 , 0.7455028 , 0.41267216],\n",
              "       [0.18652321, 0.54786676, 0.2669394 , 0.98746204, 0.3746348 ],\n",
              "       ...,\n",
              "       [0.1407244 , 0.00821428, 0.99771535, 0.1768557 , 0.28943947],\n",
              "       [0.06086601, 0.20009752, 0.619383  , 0.999402  , 0.09322514],\n",
              "       [0.36407307, 0.3246183 , 0.25206545, 0.1372863 , 0.99124235]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_y.shape, y_pred.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HMBkZRe6KHnU",
        "outputId": "05e68297-213e-4fcc-f45f-b66560cbcc97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((8000, 5), (8000, 5))"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(np.argmax(test_y,1),np.argmax(y_pred,1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q513xMETKJho",
        "outputId": "82a73fea-8882-4138-fc74-63c2eb67b69b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.856625"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embed_vect = 40\n",
        "model1 = Sequential()\n",
        "model1.add(Embedding(5000,embed_vect,input_length=40))\n",
        "model1.add(Dropout(0.3))\n",
        "model1.add(LSTM(150))\n",
        "model1.add(Dropout(0.3))\n",
        "model1.add(Dense(5,activation='sigmoid'))\n",
        "model1.compile(loss='binary_crossentropy',optimizer='adam',metrics='accuracy')\n",
        "model1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlz_PpaYKPSF",
        "outputId": "6a2d6d36-3ddc-47ac-db4f-af842c6447e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 40, 40)            200000    \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 40, 40)            0         \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 150)               114600    \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 150)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 5)                 755       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 315,355\n",
            "Trainable params: 315,355\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model1.fit(embedded_train_x,train_y,epochs=10,batch_size=128,validation_data=(embedded_test_x,test_y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "idjA-vrcKUJJ",
        "outputId": "302562fc-1751-416d-81ec-fe2a4a505c2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "94/94 [==============================] - 26s 245ms/step - loss: 0.4668 - accuracy: 0.4073 - val_loss: 0.4379 - val_accuracy: 0.4181\n",
            "Epoch 2/10\n",
            "94/94 [==============================] - 22s 239ms/step - loss: 0.4089 - accuracy: 0.5019 - val_loss: 0.3647 - val_accuracy: 0.5984\n",
            "Epoch 3/10\n",
            "94/94 [==============================] - 29s 305ms/step - loss: 0.2940 - accuracy: 0.6675 - val_loss: 0.2653 - val_accuracy: 0.7231\n",
            "Epoch 4/10\n",
            "94/94 [==============================] - 22s 237ms/step - loss: 0.2085 - accuracy: 0.7757 - val_loss: 0.2366 - val_accuracy: 0.7465\n",
            "Epoch 5/10\n",
            "94/94 [==============================] - 22s 235ms/step - loss: 0.1726 - accuracy: 0.8295 - val_loss: 0.2146 - val_accuracy: 0.7996\n",
            "Epoch 6/10\n",
            "94/94 [==============================] - 24s 252ms/step - loss: 0.1297 - accuracy: 0.8819 - val_loss: 0.1790 - val_accuracy: 0.8286\n",
            "Epoch 7/10\n",
            "94/94 [==============================] - 23s 242ms/step - loss: 0.1016 - accuracy: 0.9059 - val_loss: 0.1831 - val_accuracy: 0.8365\n",
            "Epoch 8/10\n",
            "94/94 [==============================] - 22s 237ms/step - loss: 0.0864 - accuracy: 0.9243 - val_loss: 0.1698 - val_accuracy: 0.8528\n",
            "Epoch 9/10\n",
            "94/94 [==============================] - 22s 238ms/step - loss: 0.0742 - accuracy: 0.9367 - val_loss: 0.1573 - val_accuracy: 0.8569\n",
            "Epoch 10/10\n",
            "94/94 [==============================] - 24s 254ms/step - loss: 0.0629 - accuracy: 0.9469 - val_loss: 0.1621 - val_accuracy: 0.8608\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f00fe62f2b0>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model1.save(\"model1.h5\")"
      ],
      "metadata": {
        "id": "N1gS6vOfJuDy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedded_test_x.shape, test_y.shape, embedded_train_x.shape, "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gt88tF21L70S",
        "outputId": "1075f742-7142-47a7-913e-8e6c731a1794"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((8000, 40), (8000, 5), (12000, 40))"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred1 = model1.predict(embedded_test_x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wEo5cRp7L93q",
        "outputId": "27228e0f-73f8-4e12-f7de-2e298d8fd992"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "250/250 [==============================] - 7s 25ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(np.argmax(test_y,1),np.argmax(y_pred1,1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GvwFYnbzMAxG",
        "outputId": "505688b9-4826-4573-c492-370990d20c2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.86075"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "model2 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(5000,embed_vect,input_length=40),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.GRU(32)),\n",
        "    tf.keras.layers.Dense(10, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='relu'),\n",
        "    tf.keras.layers.Dense(5, activation='sigmoid'),\n",
        "])\n",
        "model2.compile(loss='binary_crossentropy',optimizer='adam',metrics='accuracy')\n",
        "model2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IqQVx_rMMJ27",
        "outputId": "2cde90bf-5739-477c-88ba-55300c7a8cc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     (None, 40, 40)            200000    \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirectio  (None, 64)               14208     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                110       \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 10)                110       \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 10)                110       \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 5)                 55        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 215,243\n",
            "Trainable params: 215,243\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2.fit(embedded_train_x,train_y,epochs=20,batch_size=128,validation_data=(embedded_test_x,test_y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OhJFDjfDMM7r",
        "outputId": "315fe150-14d2-4dc4-8caf-68ce8e0c2ec0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "94/94 [==============================] - 17s 104ms/step - loss: 0.6663 - accuracy: 0.1343 - val_loss: 0.6198 - val_accuracy: 0.1395\n",
            "Epoch 2/20\n",
            "94/94 [==============================] - 7s 74ms/step - loss: 0.5727 - accuracy: 0.2608 - val_loss: 0.5409 - val_accuracy: 0.3121\n",
            "Epoch 3/20\n",
            "94/94 [==============================] - 9s 92ms/step - loss: 0.4988 - accuracy: 0.4238 - val_loss: 0.4850 - val_accuracy: 0.5210\n",
            "Epoch 4/20\n",
            "94/94 [==============================] - 7s 74ms/step - loss: 0.4352 - accuracy: 0.5596 - val_loss: 0.4294 - val_accuracy: 0.4320\n",
            "Epoch 5/20\n",
            "94/94 [==============================] - 8s 90ms/step - loss: 0.3741 - accuracy: 0.5003 - val_loss: 0.3813 - val_accuracy: 0.5669\n",
            "Epoch 6/20\n",
            "94/94 [==============================] - 8s 87ms/step - loss: 0.3173 - accuracy: 0.6497 - val_loss: 0.3439 - val_accuracy: 0.6564\n",
            "Epoch 7/20\n",
            "94/94 [==============================] - 7s 77ms/step - loss: 0.2782 - accuracy: 0.7198 - val_loss: 0.3377 - val_accuracy: 0.6518\n",
            "Epoch 8/20\n",
            "94/94 [==============================] - 8s 90ms/step - loss: 0.2535 - accuracy: 0.7043 - val_loss: 0.3409 - val_accuracy: 0.6407\n",
            "Epoch 9/20\n",
            "94/94 [==============================] - 7s 75ms/step - loss: 0.2366 - accuracy: 0.7071 - val_loss: 0.3428 - val_accuracy: 0.6474\n",
            "Epoch 10/20\n",
            "94/94 [==============================] - 8s 89ms/step - loss: 0.2232 - accuracy: 0.7202 - val_loss: 0.3250 - val_accuracy: 0.6586\n",
            "Epoch 11/20\n",
            "94/94 [==============================] - 9s 95ms/step - loss: 0.2122 - accuracy: 0.7381 - val_loss: 0.3286 - val_accuracy: 0.6658\n",
            "Epoch 12/20\n",
            "94/94 [==============================] - 7s 76ms/step - loss: 0.1995 - accuracy: 0.7602 - val_loss: 0.3302 - val_accuracy: 0.6836\n",
            "Epoch 13/20\n",
            "94/94 [==============================] - 9s 91ms/step - loss: 0.1887 - accuracy: 0.8032 - val_loss: 0.3323 - val_accuracy: 0.7476\n",
            "Epoch 14/20\n",
            "94/94 [==============================] - 8s 80ms/step - loss: 0.1792 - accuracy: 0.8485 - val_loss: 0.3653 - val_accuracy: 0.7326\n",
            "Epoch 15/20\n",
            "94/94 [==============================] - 8s 83ms/step - loss: 0.1718 - accuracy: 0.8565 - val_loss: 0.3228 - val_accuracy: 0.7713\n",
            "Epoch 16/20\n",
            "94/94 [==============================] - 9s 99ms/step - loss: 0.1607 - accuracy: 0.8756 - val_loss: 0.3564 - val_accuracy: 0.7768\n",
            "Epoch 17/20\n",
            "94/94 [==============================] - 7s 76ms/step - loss: 0.1538 - accuracy: 0.8839 - val_loss: 0.3816 - val_accuracy: 0.7921\n",
            "Epoch 18/20\n",
            "94/94 [==============================] - 9s 91ms/step - loss: 0.1468 - accuracy: 0.8988 - val_loss: 0.3868 - val_accuracy: 0.7971\n",
            "Epoch 19/20\n",
            "94/94 [==============================] - 7s 76ms/step - loss: 0.1431 - accuracy: 0.9044 - val_loss: 0.4636 - val_accuracy: 0.7666\n",
            "Epoch 20/20\n",
            "94/94 [==============================] - 8s 81ms/step - loss: 0.1387 - accuracy: 0.9118 - val_loss: 0.5062 - val_accuracy: 0.7954\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f00fcaf1a90>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2.save(\"model2.h5\")"
      ],
      "metadata": {
        "id": "25NuwSYXK_Yn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred2 = model2.predict(embedded_test_x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mRMhgGspNemH",
        "outputId": "518f9206-6e9a-4ee4-bcee-acab327bf7cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "250/250 [==============================] - 3s 9ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(np.argmax(test_y,1),np.argmax(y_pred2,1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qycKLAJrNgCa",
        "outputId": "0e857913-2b36-4ee1-d4d3-61378786360a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.795375"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "y_final1 = []\n",
        "for counter,i in enumerate(zip(y_pred,y_pred1,y_pred2)):\n",
        "  y_new1 = []\n",
        "  for j,h,z in zip(i[0],i[1],i[2]):\n",
        "    y_new1.append(max([j,h,z]))\n",
        "  y_final1.append(y_new1)\n",
        "\n",
        "for counter,i in enumerate(y_final1):\n",
        "  max_value1 = numpy.argmax(i)\n",
        "  y_final1[counter] = [1 if x==max_value1 else 0 for x,z in enumerate(i)]\n",
        "\n",
        "y_final1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T0Vgh1beNh6Q",
        "outputId": "ab4df510-1282-4c73-ca45-564f88dbac5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0, 0, 0, 1, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 1, 0, 0, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 1, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 1, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 1, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 1, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 1, 0, 0, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 1, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 1, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 1, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 1, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 1, 0, 0, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 1, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 1, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 1, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 1, 0, 0, 0],\n",
              " [0, 1, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 1, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 1, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 1, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 1, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 1, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 1, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 1, 0, 0, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 1, 0, 0, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 1, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 1, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 1, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 1, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 1, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 1, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 1, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 1, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 1, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 1, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(np.argmax(test_y,1),np.argmax(y_final1,1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5zlHMldNv7w",
        "outputId": "0b4cc326-6da7-4770-e228-958a961c8592"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.86425"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_message = \"Everyone is avoiding me i am not aware that how can i hope on to work with them. They are not even talking to me which makes me a bit more worried.\""
      ],
      "metadata": {
        "id": "d1mrPzLTegOY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stringo = user_message.lower() "
      ],
      "metadata": {
        "id": "znpEc4DVe14m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resulto = \" \"\n",
        "for i in stringo.split():\n",
        "  if i not in stopper:\n",
        "    resulto=resulto+i+\" \"\n",
        "resulto = resulto.strip()"
      ],
      "metadata": {
        "id": "Z1RoIl2_fV5V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resulto"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "WRxBizb2fnTM",
        "outputId": "5b2ad3b9-fa6f-4701-b5d0-e7cd6ac505ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'everyone avoiding aware hope work them. even talking makes bit worried.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_sento = \"\"\n",
        "for i in  resulto.split(\" \"):\n",
        "  new_sento = new_sento+lemmatizer.lemmatize(i)+\" \""
      ],
      "metadata": {
        "id": "0OXjdQsCf3_B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_rep_o = [one_hot(new_sento,5000)]"
      ],
      "metadata": {
        "id": "2Gm-6xb7gn44"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent_length = 40\n",
        "embedded_x_o = pad_sequences(x_rep_o,padding='pre',maxlen=sent_length)"
      ],
      "metadata": {
        "id": "_il5s6BAhHbd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model = tf.keras.models.load_model('model.h5')\n",
        "loaded_model1 = tf.keras.models.load_model('model1.h5')\n",
        "loaded_model2 = tf.keras.models.load_model('model2.h5')"
      ],
      "metadata": {
        "id": "xDAz5XGqhSlX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ypredo = loaded_model.predict(embedded_x_o)\n",
        "ypredo1 = loaded_model1.predict(embedded_x_o)\n",
        "ypredo2 = loaded_model2.predict(embedded_x_o)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f-FWwhIihf8W",
        "outputId": "50f290cb-9500-412d-b6b4-c2ed15bf7c79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 1s 654ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(ypredo,\n",
        "ypredo1,\n",
        "ypredo2,)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MUGsyck-jaVJ",
        "outputId": "30fbe165-5fd0-4f25-e874-75db8a50b5ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.14922944 0.63359654 0.46439943 0.9807099  0.29330122]] [[0.02800571 0.49864915 0.0129452  0.40409312 0.00766416]] [[0.02800571 0.49864915 0.0129452  0.40409312 0.00766416]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "y_final1o = []\n",
        "for counter,i in enumerate(zip(ypredo,ypredo1,ypredo2)):\n",
        "  y_new1o = []\n",
        "  for j,h,z in zip(i[0],i[1],i[2]):\n",
        "    y_new1o.append(max([j,h,z]))\n",
        "  y_final1o.append(y_new1o)\n",
        "\n",
        "y_final1o\n",
        "for counter,i in enumerate(y_final1o):\n",
        "  max_value1 = numpy.argmax(i)\n",
        "  y_final1o[counter] = [1 if x==max_value1 else 0 for x,z in enumerate(i)]\n",
        "\n",
        "y_final1o"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7RCh-EJJkFFI",
        "outputId": "d215b8a0-4d3c-4ede-ab12-a74166b93626"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0.14922944, 0.63359654, 0.46439943, 0.9807099, 0.29330122]]"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-lk2gxstlWqW",
        "outputId": "ead63e4e-232a-45d1-9c7c-b5d04b122b3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0, 0, 0, 1, 0]]"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.argmax(y_final1o,1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aIE5jC69lqno",
        "outputId": "dfbd89d5-f7f0-49ca-f7a6-7d3267f6a60e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3])"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    }
  ]
}